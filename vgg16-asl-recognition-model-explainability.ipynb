{"cells":[{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #76503d;\n","              box-shadow: rgba(0, 0, 0, 0.19) 0px 10px 5px, rgba(0, 0, 0, 0.15) 0px 6px 6px;\">\n","    <h1 id = \"title\"\n","        style = \"padding: 15px; \n","                 text-align:center;\n","                 color: White;\n","                 font-size: 28px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">VGG16 ASL Recognition + Model Explainability\n","        <a class=\"anchor-link\" id=\"title\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#title\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["![American Sign Language History | Woodhaven](https://www.woodhaventeam.org/wp-content/uploads/2022/04/GettyImages-1182224687-scaled.jpg)"]},{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #c7a48b;\n","              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n","    <h1 id = \"preparation\"\n","        style = \"padding: 13px; \n","                 color: White;\n","                 font-size: 24px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">1. | Preparation\n","        <a class=\"anchor-link\" id=\"preparation\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#preparation\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:06.829297Z","iopub.status.busy":"2023-05-04T22:55:06.82861Z","iopub.status.idle":"2023-05-04T22:55:18.459697Z","shell.execute_reply":"2023-05-04T22:55:18.45641Z","shell.execute_reply.started":"2023-05-04T22:55:06.829264Z"},"trusted":true},"outputs":[],"source":["!pip install imutils"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:21.490927Z","iopub.status.busy":"2023-05-04T22:55:21.490542Z","iopub.status.idle":"2023-05-04T22:55:28.649756Z","shell.execute_reply":"2023-05-04T22:55:28.648871Z","shell.execute_reply.started":"2023-05-04T22:55:21.490894Z"},"trusted":true},"outputs":[],"source":["# Import Libraries\n","\n","# Warning\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Main\n","import os\n","import glob\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import gc\n","import string\n","import time\n","import random\n","import imutils\n","from PIL import Image\n","from tqdm import tqdm\n","tqdm.pandas()\n","\n","# Visualization\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import plotly\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","from sklearn.manifold import TSNE\n","\n","# Model\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from keras.models import load_model, Model\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:33.775265Z","iopub.status.busy":"2023-05-04T22:55:33.774545Z","iopub.status.idle":"2023-05-04T22:55:33.782905Z","shell.execute_reply":"2023-05-04T22:55:33.779367Z","shell.execute_reply.started":"2023-05-04T22:55:33.775235Z"},"trusted":true},"outputs":[],"source":["# Configuration\n","class CFG:\n","    batch_size = 64\n","    img_height = 64\n","    img_width = 64\n","    epochs = 10\n","    num_classes = 29\n","    img_channels = 3\n","    \n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)"]},{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #c7a48b;\n","              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n","    <h1 id = \"dataset\"\n","        style = \"padding: 13px; \n","                 color: White;\n","                 font-size: 24px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">2. | Dataset\n","        <a class=\"anchor-link\" id=\"dataset\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#dataset\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">2.1. Data Exploration</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:36.199362Z","iopub.status.busy":"2023-05-04T22:55:36.199023Z","iopub.status.idle":"2023-05-04T22:55:36.20791Z","shell.execute_reply":"2023-05-04T22:55:36.206915Z","shell.execute_reply.started":"2023-05-04T22:55:36.199334Z"},"trusted":true},"outputs":[],"source":["# Labels\n","TRAIN_PATH = \"/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\n","labels = []\n","alphabet = list(string.ascii_uppercase)\n","labels.extend(alphabet)\n","labels.extend([\"del\", \"nothing\", \"space\"])\n","print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-04T23:14:18.90552Z","iopub.status.busy":"2023-05-04T23:14:18.90518Z","iopub.status.idle":"2023-05-04T23:14:18.912337Z","shell.execute_reply":"2023-05-04T23:14:18.911486Z","shell.execute_reply.started":"2023-05-04T23:14:18.905492Z"},"trusted":true},"outputs":[],"source":["def sample_images(labels):\n","    # Create Subplots\n","    y_size = 12\n","    if(len(labels)<10):\n","        y_size = y_size * len(labels) / 10\n","    fig, axs = plt.subplots(len(labels), 9, figsize=(y_size, 13))\n","\n","    for i, label in enumerate(labels):\n","        axs[i, 0].text(0.5, 0.5, label, ha='center', va='center', fontsize=8)\n","        axs[i, 0].axis('off')\n","\n","        label_path = os.path.join(TRAIN_PATH, label)\n","        list_files = os.listdir(label_path)\n","\n","        for j in range(8):\n","            img_label = cv2.imread(os.path.join(label_path, list_files[j]))\n","            img_label = cv2.cvtColor(img_label, cv2.COLOR_BGR2RGB)\n","            axs[i, j+1].imshow(img_label)\n","            axs[i, j+1].axis(\"off\")\n","\n","    # Title\n","    plt.suptitle(\"Sample Images in ASL Alphabet Dataset\", x=0.55, y=0.92)\n","\n","    # Show\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-04T23:14:19.523125Z","iopub.status.busy":"2023-05-04T23:14:19.522792Z","iopub.status.idle":"2023-05-04T23:14:22.544357Z","shell.execute_reply":"2023-05-04T23:14:22.543556Z","shell.execute_reply.started":"2023-05-04T23:14:19.523097Z"},"trusted":true},"outputs":[],"source":["sample_images(labels[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-04T23:14:27.412983Z","iopub.status.busy":"2023-05-04T23:14:27.41262Z","iopub.status.idle":"2023-05-04T23:14:30.539888Z","shell.execute_reply":"2023-05-04T23:14:30.539018Z","shell.execute_reply.started":"2023-05-04T23:14:27.412957Z"},"trusted":true},"outputs":[],"source":["sample_images(labels[10:20])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-04T23:14:30.542782Z","iopub.status.busy":"2023-05-04T23:14:30.541322Z","iopub.status.idle":"2023-05-04T23:14:33.219718Z","shell.execute_reply":"2023-05-04T23:14:33.218896Z","shell.execute_reply.started":"2023-05-04T23:14:30.542749Z"},"trusted":true},"outputs":[],"source":["sample_images(labels[20:])"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">2.2. Data Preprocessing</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:53.94664Z","iopub.status.busy":"2023-05-04T22:55:53.946098Z","iopub.status.idle":"2023-05-04T22:55:58.116691Z","shell.execute_reply":"2023-05-04T22:55:58.115751Z","shell.execute_reply.started":"2023-05-04T22:55:53.946608Z"},"trusted":true},"outputs":[],"source":["# Create Metadata\n","list_path = []\n","list_labels = []\n","for label in labels:\n","    label_path = os.path.join(TRAIN_PATH, label, \"*\")\n","    image_files = glob.glob(label_path)\n","    \n","    sign_label = [label] * len(image_files)\n","    \n","    list_path.extend(image_files)\n","    list_labels.extend(sign_label)\n","\n","metadata = pd.DataFrame({\n","    \"image_path\": list_path,\n","    \"label\": list_labels\n","})\n","\n","metadata"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:58.119577Z","iopub.status.busy":"2023-05-04T22:55:58.118925Z","iopub.status.idle":"2023-05-04T22:55:58.272469Z","shell.execute_reply":"2023-05-04T22:55:58.271636Z","shell.execute_reply.started":"2023-05-04T22:55:58.119526Z"},"trusted":true},"outputs":[],"source":["# Split Dataset to Train 0.7, Val 0.15, and Test 0.15\n","X_train, X_test, y_train, y_test = train_test_split(\n","    metadata[\"image_path\"], metadata[\"label\"], \n","    test_size=0.15, \n","    random_state=2023, \n","    shuffle=True, \n","    stratify=metadata[\"label\"]\n",")\n","data_train = pd.DataFrame({\n","    \"image_path\": X_train,\n","    \"label\": y_train\n","})\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    data_train[\"image_path\"], data_train[\"label\"],\n","    test_size=0.15/0.70,\n","    random_state=2023,\n","    shuffle=True,\n","    stratify=data_train[\"label\"]\n",")\n","data_train = pd.DataFrame({\n","    \"image_path\": X_train,\n","    \"label\": y_train\n","})\n","data_val = pd.DataFrame({\n","    \"image_path\": X_val,\n","    \"label\": y_val\n","})\n","data_test = pd.DataFrame({\n","    \"image_path\": X_test,\n","    \"label\": y_test\n","})\n","\n","display(data_train)\n","display(data_val)\n","display(data_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:58.274467Z","iopub.status.busy":"2023-05-04T22:55:58.273884Z","iopub.status.idle":"2023-05-04T22:55:58.282124Z","shell.execute_reply":"2023-05-04T22:55:58.281067Z","shell.execute_reply.started":"2023-05-04T22:55:58.274432Z"},"trusted":true},"outputs":[],"source":["# Data Augmentation (Just Rescale)\n","def data_augmentation():\n","    datagen = ImageDataGenerator(rescale=1/255.,)\n","    # Training Dataset\n","    train_generator = datagen.flow_from_dataframe(\n","        data_train,\n","        directory=\"./\",\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        class_mode=\"categorical\",\n","        batch_size=CFG.batch_size,\n","        target_size=(CFG.img_height, CFG.img_width),\n","    )\n","\n","    # Validation Dataset\n","    validation_generator = datagen.flow_from_dataframe(\n","        data_val,\n","        directory=\"./\",\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        class_mode=\"categorical\",\n","        batch_size=CFG.batch_size,\n","        target_size=(CFG.img_height, CFG.img_width),\n","    )\n","    \n","    # Testing Dataset\n","    test_generator = datagen.flow_from_dataframe(\n","        data_test,\n","        directory=\"./\",\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        class_mode=\"categorical\",\n","        batch_size=1,\n","        target_size=(CFG.img_height, CFG.img_width),\n","        shuffle=False\n","    )\n","    \n","    return train_generator, validation_generator, test_generator"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:55:58.284044Z","iopub.status.busy":"2023-05-04T22:55:58.283513Z","iopub.status.idle":"2023-05-04T22:58:50.78268Z","shell.execute_reply":"2023-05-04T22:58:50.781814Z","shell.execute_reply.started":"2023-05-04T22:55:58.284004Z"},"trusted":true},"outputs":[],"source":["seed_everything(2023)\n","train_generator, validation_generator, test_generator = data_augmentation()"]},{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #c7a48b;\n","              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n","    <h1 id = \"model-training\"\n","        style = \"padding: 13px; \n","                 color: White;\n","                 font-size: 24px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">3. | Model Training\n","        <a class=\"anchor-link\" id=\"model-training\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#model-training\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">3.1. VGG16</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T01:17:02.866282Z","iopub.status.busy":"2023-05-04T01:17:02.865927Z","iopub.status.idle":"2023-05-04T01:17:07.18781Z","shell.execute_reply":"2023-05-04T01:17:07.186962Z","shell.execute_reply.started":"2023-05-04T01:17:02.866252Z"},"trusted":true},"outputs":[],"source":["# Load VGG16 model and modify for ASL recognition\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(CFG.img_height, CFG.img_width, CFG.img_channels))\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(29, activation='softmax')(x)\n","\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","display(model.summary())\n","display(tf.keras.utils.plot_model(model, to_file='vgg16.png', show_shapes=True))"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">3.2. Training</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T01:17:14.826548Z","iopub.status.busy":"2023-05-04T01:17:14.82622Z","iopub.status.idle":"2023-05-04T01:17:14.844717Z","shell.execute_reply":"2023-05-04T01:17:14.843878Z","shell.execute_reply.started":"2023-05-04T01:17:14.826522Z"},"trusted":true},"outputs":[],"source":["# Compile and train the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks\n","checkpoint = ModelCheckpoint('asl_vgg16_best_weights.h5', save_best_only=True, monitor='val_accuracy', mode='max')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T01:17:20.905335Z","iopub.status.busy":"2023-05-04T01:17:20.904983Z","iopub.status.idle":"2023-05-04T01:40:57.733301Z","shell.execute_reply":"2023-05-04T01:40:57.732427Z","shell.execute_reply.started":"2023-05-04T01:17:20.905306Z"},"trusted":true},"outputs":[],"source":["# Train the Model\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // CFG.batch_size,\n","    epochs=CFG.epochs,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // CFG.batch_size,\n","    callbacks=[checkpoint]\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #c7a48b;\n","              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n","    <h1 id = \"model-evaluation\"\n","        style = \"padding: 13px; \n","                 color: White;\n","                 font-size: 24px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">4. | Model Evaluation\n","        <a class=\"anchor-link\" id=\"model-evaluation\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#model-evaluation\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">4.1. Model Testing</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T01:51:30.90221Z","iopub.status.busy":"2023-05-04T01:51:30.901744Z","iopub.status.idle":"2023-05-04T01:53:08.428388Z","shell.execute_reply":"2023-05-04T01:53:08.427516Z","shell.execute_reply.started":"2023-05-04T01:51:30.902176Z"},"trusted":true},"outputs":[],"source":["scores = model.evaluate(test_generator)\n","print(\"%s: %.2f%%\" % (\"Evaluate Test Accuracy\", scores[1]*100))"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">4.2. Training Loss and Metrics</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Visualize Training and Validation Results\n","\n","# Create Subplot\n","fig = make_subplots(\n","        rows=1, cols=2,\n","        subplot_titles=[\"Model Loss\", \"Model Accuracy\"], \n",")\n","\n","# Configuration Plot\n","class PlotCFG:\n","    marker_size = 8\n","    line_size = 2\n","    train_color = \"#76503d\"\n","    valid_color = \"#deb392\"\n","\n","# Loss Plot\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","fig.add_trace(\n","    go.Scatter(\n","        x=np.arange(1, len(loss)+1), y=loss,\n","        mode=\"markers+lines\",\n","        marker=dict(\n","            color=PlotCFG.train_color, size=PlotCFG.marker_size,\n","            line=dict(color=\"White\", width=0.5)\n","        ),\n","        line=dict(color=PlotCFG.train_color, width=PlotCFG.line_size),\n","        name=\"Training Loss\"\n","    ), row=1, col=1\n",")\n","fig.add_trace(\n","    go.Scatter(\n","        x=np.arange(1, len(val_loss)+1), y=val_loss,\n","        mode=\"markers+lines\",\n","        marker=dict(\n","            color=PlotCFG.valid_color, size=PlotCFG.marker_size,\n","            line=dict(color=\"White\", width=0.5)\n","        ),\n","        line=dict(color=PlotCFG.valid_color, width=PlotCFG.line_size),\n","        name=\"Validation Loss\"\n","    ), row=1, col=1\n",")\n","\n","# Accuracy Plot\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","fig.add_trace(\n","    go.Scatter(\n","        x=np.arange(1, len(acc)+1), y=acc,\n","        mode=\"markers+lines\",\n","        marker=dict(\n","            color=PlotCFG.train_color, size=PlotCFG.marker_size,\n","            line=dict(color=\"White\", width=0.5)\n","        ),\n","        line=dict(color=PlotCFG.train_color, width=PlotCFG.line_size),\n","        name=\"Training Accuracy\"\n","    ), row=1, col=2\n",")\n","fig.add_trace(\n","    go.Scatter(\n","        x=np.arange(1, len(val_acc)+1), y=val_acc,\n","        mode=\"markers+lines\",\n","        marker=dict(\n","            color=PlotCFG.valid_color, size=PlotCFG.marker_size,\n","            line=dict(color=\"White\", width=0.5)\n","        ),\n","        line=dict(color=PlotCFG.valid_color, width=PlotCFG.line_size),\n","        name=\"Validation Accuracy\"\n","    ), row=1, col=2\n",")\n","\n","# Update Axes\n","fig.update_xaxes(title=\"Epochs\", linecolor=\"Black\", ticks=\"outside\", row=1, col=1)\n","fig.update_xaxes(title=\"Epochs\", linecolor=\"Black\", ticks=\"outside\", row=1, col=2)\n","fig.update_yaxes(title=\"Categorical Loss\", linecolor=\"Black\", ticks=\"outside\", row=1, col=1)\n","fig.update_yaxes(title=\"Accuracy\", linecolor=\"Black\", ticks=\"outside\", row=1, col=2)\n","\n","# Update Layout\n","fig.update_layout(\n","    title=\"Training Loss and Metrics\", title_x=0.5,\n","    width=950, height=400,\n","    showlegend=False,\n","    plot_bgcolor=\"White\",\n","    paper_bgcolor=\"White\"\n",")\n","\n","# Show\n","fig.show(iframe_connected=True)"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">4.3. Confusion Matrix</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T22:58:57.627468Z","iopub.status.busy":"2023-05-04T22:58:57.627139Z","iopub.status.idle":"2023-05-04T23:00:55.485733Z","shell.execute_reply":"2023-05-04T23:00:55.484807Z","shell.execute_reply.started":"2023-05-04T22:58:57.627443Z"},"trusted":true},"outputs":[],"source":["# Confusion Matrix\n","fine_tuned_model = load_model(\"/kaggle/working/asl_vgg16_best_weights.h5\")\n","predictions = fine_tuned_model.predict(test_generator)\n","\n","# Get the true labels from the generator\n","true_labels = test_generator.classes\n","\n","# Compute the confusion matrix using tf.math.confusion_matrix\n","confusion_matrix = tf.math.confusion_matrix(\n","        labels=true_labels,\n","        predictions=predictions.argmax(axis=1),\n","        num_classes=29)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:05:53.200388Z","iopub.status.busy":"2023-05-04T23:05:53.199396Z","iopub.status.idle":"2023-05-04T23:05:53.40415Z","shell.execute_reply":"2023-05-04T23:05:53.40316Z","shell.execute_reply.started":"2023-05-04T23:05:53.200347Z"},"trusted":true},"outputs":[],"source":["# Create Figure\n","fig = go.Figure()\n","\n","# Heatmap\n","fig.add_trace(\n","    go.Heatmap(\n","        z=confusion_matrix,\n","        x=labels,\n","        y=labels,\n","        text=confusion_matrix,\n","        texttemplate=\"<b>%{text}</b>\",\n","        textfont={\"size\":8},\n","        colorscale=[[0, '#f4f4f4'],[1.0, '#76503d']],\n","        showscale = False,\n","        ygap = 5,\n","        xgap = 5,\n","        hovertemplate=\n","        '''\n","        Actual: %{y}<br>\n","        Predicted: %{x}<br>\n","        Total: %{text}\n","        ''',\n","        name=\"Confusion Matrix\"\n","    )\n",")\n","\n","# Update Axes\n","fig.update_xaxes(title=\"<b>Predicted Values</b>\", tickfont_size=10)\n","fig.update_yaxes(title=\"<b>Actual Values</b>\", tickfont_size=10)\n","\n","# Update Layout\n","fig.update_layout(title_text='Confusion Matrix', title_x=0.5, font_size=14,\n","                  width=1050, \n","                  height=1115,\n","                  plot_bgcolor='white',\n","                  showlegend=False,\n",")\n","\n","# Show\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div style = \"color: Black; \n","              display: fill;\n","              border-radius: 12px;\n","              background-color: #c7a48b;\n","              box-shadow: rgba(0, 0, 0, 0.15) 0px 10px 5px, rgba(0, 0, 0, 0.12) 0px 6px 6px;\">\n","    <h1 id = \"model-explainability\"\n","        style = \"padding: 13px; \n","                 color: White;\n","                 font-size: 24px;\n","                 font-weight: bold;\n","                 font-family: Calibri;\">5. | Model Explainability\n","        <a class=\"anchor-link\" id=\"model-explainability\" href=\"https://www.kaggle.com/code/harits/vgg16-asl-recognition-model-explainability#model-explainability\">¶</a>\n","    </h1>\n","</div>"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">5.1. t-SNE Visualization</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:06:00.556498Z","iopub.status.busy":"2023-05-04T23:06:00.556161Z","iopub.status.idle":"2023-05-04T23:06:00.605485Z","shell.execute_reply":"2023-05-04T23:06:00.604744Z","shell.execute_reply.started":"2023-05-04T23:06:00.55647Z"},"trusted":true},"outputs":[],"source":["dense_model = Model(inputs=fine_tuned_model.inputs, outputs=fine_tuned_model.layers[-3].output)\n","dense_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:06:01.471697Z","iopub.status.busy":"2023-05-04T23:06:01.471321Z","iopub.status.idle":"2023-05-04T23:06:01.476984Z","shell.execute_reply":"2023-05-04T23:06:01.475943Z","shell.execute_reply.started":"2023-05-04T23:06:01.471665Z"},"trusted":true},"outputs":[],"source":["print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:31:50.689987Z","iopub.status.busy":"2023-05-04T23:31:50.68941Z","iopub.status.idle":"2023-05-04T23:34:32.653471Z","shell.execute_reply":"2023-05-04T23:34:32.652572Z","shell.execute_reply.started":"2023-05-04T23:31:50.689947Z"},"trusted":true},"outputs":[],"source":["# Extract Features in Dense Layer\n","def dense_feature_prediction(img_path):\n","    img = load_img(img_path, target_size=(CFG.img_height, CFG.img_width))\n","    img = img_to_array(img)\n","    img = img / 255.\n","    img = np.expand_dims(img, axis=0)\n","    dense_feature = dense_model.predict(img, verbose=0)[0]\n","    return dense_feature\n","\n","reduction_data = pd.DataFrame()\n","for label in labels:\n","    label_data = data_test[data_test[\"label\"]==label][:100]\n","    reduction_data = reduction_data.append(label_data)\n","\n","reduction_data = reduction_data.reset_index(drop=True)\n","display(reduction_data)\n","\n","dense_features = reduction_data[\"image_path\"].progress_apply(dense_feature_prediction)\n","dense_features = pd.DataFrame.from_records(dense_features.values, index=dense_features.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:34:36.666957Z","iopub.status.busy":"2023-05-04T23:34:36.666613Z","iopub.status.idle":"2023-05-04T23:34:47.162091Z","shell.execute_reply":"2023-05-04T23:34:47.161342Z","shell.execute_reply.started":"2023-05-04T23:34:36.666929Z"},"trusted":true},"outputs":[],"source":["# tSNE Dimensional Reduction\n","tsne = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n","tsne_features = tsne.fit_transform(dense_features)\n","tsne_features = pd.DataFrame(tsne_features, columns=[\"tsne_feat_0\", \"tsne_feat_1\"])\n","reduction_data[[\"tsne_feat_0\", \"tsne_feat_1\"]] = tsne_features\n","reduction_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:34:54.836051Z","iopub.status.busy":"2023-05-04T23:34:54.835467Z","iopub.status.idle":"2023-05-04T23:34:54.986394Z","shell.execute_reply":"2023-05-04T23:34:54.98553Z","shell.execute_reply.started":"2023-05-04T23:34:54.836018Z"},"trusted":true},"outputs":[],"source":["# Scatter Plot\n","list_colors = [\"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FFFF00\", \"#FF00FF\", \"#00FFFF\", \"#FF4500\", \"#800080\", \"#32CD32\", \"#8B0000\", \n","               \"#000080\", \"#808000\", \"#FF6347\", \"#008080\", \"#FF1493\", \"#7FFF00\", \"#D2691E\", \"#9400D3\", \"#B22222\", \"#ADFF2F\",\n","               \"#ADD8E6\", \"#FF69B4\", \"#F0E68C\", \"#4682B4\", \"#9ACD32\", \"#800000\", \"#FFD700\", \"#20B2AA\", \"#A52A2A\"\n","              ]\n","fig = px.scatter(\n","    reduction_data, x=\"tsne_feat_0\", y=\"tsne_feat_1\", color='label', color_discrete_sequence=list_colors\n",")\n","\n","fig.update_traces(marker=dict(size=8),)\n","\n","# Update Axes\n","fig.update_xaxes(title=\"\", linecolor=\"Black\", zeroline=False, mirror=True)\n","fig.update_yaxes(title=\"\", linecolor=\"Black\", zeroline=False, mirror=True)\n","\n","# Update Layout\n","fig.update_layout(\n","    title_text=\"t-SNE Visualization\", title_x=0.5,\n","    width=900, height=900,\n","    plot_bgcolor='White',\n","    coloraxis_showscale=False,\n",")\n","\n","# Show\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["<div>\n","    <h2 style = \"color: #c7a48b; font-size: 22px; font-family: Calibri; font-weight: bold;\">5.2. Class Activation Maps (Grad-CAM)</h2>\n","</div>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-05-04T23:08:05.760757Z","iopub.status.busy":"2023-05-04T23:08:05.7604Z","iopub.status.idle":"2023-05-04T23:08:05.772516Z","shell.execute_reply":"2023-05-04T23:08:05.771638Z","shell.execute_reply.started":"2023-05-04T23:08:05.760729Z"},"trusted":true},"outputs":[],"source":["# https://pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/\n","class GradCAM:\n","    def __init__(self, model, classIdx, layerName=None):\n","        # store the model, the class index used to measure the class\n","        # activation map, and the layer to be used when visualizing\n","        # the class activation map\n","        self.model = model\n","        self.classIdx = classIdx\n","        self.layerName = layerName\n","        \n","        # if the layer name is None, attempt to automatically find\n","        # the target output layer\n","        if self.layerName is None:\n","            self.layerName = self.find_target_layer()\n","            \n","    def find_target_layer(self):\n","        # attempt to find the final convolutional layer in the network\n","        # by looping over the layers of the network in reverse order\n","        for layer in reversed(self.model.layers):\n","            # check to see if the layer has a 4D output\n","            if len(layer.output_shape) == 4:\n","                return layer.name\n","            \n","        # otherwise, we could not find a 4D layer so the GradCAM\n","        # algorithm cannot be applied\n","        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n","        \n","    def compute_heatmap(self, image, eps=1e-8):\n","        # construct our gradient model by supplying (1) the inputs\n","        # to our pre-trained model, (2) the output of the (presumably)\n","        # final 4D layer in the network, and (3) the output of the\n","        # softmax activations from the model\n","        gradModel = Model(\n","            inputs=[self.model.inputs],\n","            outputs=[self.model.get_layer(self.layerName).output, self.model.output])\n","        \n","        # record operations for automatic differentiation\n","        with tf.GradientTape() as tape:\n","            # cast the image tensor to a float-32 data type, pass the\n","            # image through the gradient model, and grab the loss\n","            # associated with the specific class index\n","            inputs = tf.cast(image, tf.float32)\n","            (convOutputs, predictions) = gradModel(inputs)\n","            loss = predictions[:, self.classIdx]\n","            \n","        # use automatic differentiation to compute the gradients\n","        grads = tape.gradient(loss, convOutputs)\n","        \n","        # compute the guided gradients\n","        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n","        castGrads = tf.cast(grads > 0, \"float32\")\n","        guidedGrads = castConvOutputs * castGrads * grads\n","        \n","        # the convolution and guided gradients have a batch dimension\n","        # (which we don't need) so let's grab the volume itself and\n","        # discard the batch\n","        convOutputs = convOutputs[0]\n","        guidedGrads = guidedGrads[0]\n","        \n","        # compute the average of the gradient values, and using them\n","        # as weights, compute the ponderation of the filters with\n","        # respect to the weights\n","        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n","        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n","        \n","        # grab the spatial dimensions of the input image and resize\n","        # the output class activation map to match the input image\n","        # dimensions\n","        (w, h) = (image.shape[2], image.shape[1])\n","        heatmap = cv2.resize(cam.numpy(), (w, h))\n","        \n","        # normalize the heatmap such that all values lie in the range\n","        # [0, 1], scale the resulting values to the range [0, 255],\n","        # and then convert to an unsigned 8-bit integer\n","        numer = heatmap - np.min(heatmap)\n","        denom = (heatmap.max() - heatmap.min()) + eps\n","        heatmap = numer / denom\n","        heatmap = (heatmap * 255).astype(\"uint8\")\n","        \n","        # return the resulting heatmap to the calling function\n","        return heatmap\n","    \n","    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n","        colormap=cv2.COLORMAP_VIRIDIS):\n","        \n","        # apply the supplied color map to the heatmap and then\n","        # overlay the heatmap on the input image\n","        heatmap = cv2.applyColorMap(heatmap, colormap)\n","        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n","        \n","        # return a 2-tuple of the color mapped heatmap and the output,\n","        # overlaid image\n","        return (heatmap, output)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:24:26.478179Z","iopub.status.busy":"2023-05-04T23:24:26.477822Z","iopub.status.idle":"2023-05-04T23:24:26.490209Z","shell.execute_reply":"2023-05-04T23:24:26.489311Z","shell.execute_reply.started":"2023-05-04T23:24:26.478151Z"},"trusted":true},"outputs":[],"source":["def gradcam_images(labels):\n","    # Create Subplots\n","    fig, axs = plt.subplots(len(labels), 7, figsize=(12, 10))\n","\n","    for i, label in enumerate(labels):\n","        axs[i, 0].text(0.5, 0.5, label, ha='center', va='center', fontsize=8)\n","        axs[i, 0].axis('off')\n","        \n","        label_data = data_test[data_test[\"label\"]==label][:2].reset_index(drop=True)\n","\n","        for j in range(2):\n","            # Read Original Image\n","            orig = cv2.imread(label_data[\"image_path\"][j])\n","            orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n","            \n","            # Preprocess and Predict Label from Image\n","            img = load_img(label_data[\"image_path\"][j], target_size=(CFG.img_height, CFG.img_width))\n","            img = img_to_array(img) / 255.\n","            img = np.expand_dims(img, axis=0)\n","            img_label_ci = fine_tuned_model.predict(img, verbose=0)\n","            img_label = np.argmax(img_label_ci[0])\n","            \n","            # Compute Heatmap using GradCAM\n","            cam = GradCAM(fine_tuned_model, img_label)\n","            heatmap = cam.compute_heatmap(img)\n","            \n","            # Overlay Heatmap with Original Image\n","            heatmap = cv2.resize(heatmap, (orig.shape[1], orig.shape[0]))\n","            heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n","            (heatmap, output) = cam.overlay_heatmap(heatmap, orig, alpha=0.5)\n","            \n","            # Show Original, Heatmap, and Overlap Heatmap Images\n","            axs[i, j*3+1].imshow(orig)\n","            axs[i, j*3+1].axis(\"off\")\n","            axs[i, j*3+2].imshow(heatmap)\n","            axs[i, j*3+2].axis(\"off\")\n","            axs[i, j*3+3].imshow(output)\n","            axs[i, j*3+3].axis(\"off\")\n","\n","    # Title\n","    plt.suptitle(\"Class Activation Maps (GradCAM) in Test Images\", x=0.55, y=0.92)\n","\n","    # Show\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:24:38.590714Z","iopub.status.busy":"2023-05-04T23:24:38.590344Z","iopub.status.idle":"2023-05-04T23:24:40.828272Z","shell.execute_reply":"2023-05-04T23:24:40.827298Z","shell.execute_reply.started":"2023-05-04T23:24:38.590683Z"},"trusted":true},"outputs":[],"source":["gradcam_images(labels[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:24:40.831791Z","iopub.status.busy":"2023-05-04T23:24:40.830115Z","iopub.status.idle":"2023-05-04T23:24:43.703441Z","shell.execute_reply":"2023-05-04T23:24:43.699869Z","shell.execute_reply.started":"2023-05-04T23:24:40.831758Z"},"trusted":true},"outputs":[],"source":["gradcam_images(labels[5:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-04T23:25:14.102735Z","iopub.status.busy":"2023-05-04T23:25:14.102346Z","iopub.status.idle":"2023-05-04T23:25:16.237251Z","shell.execute_reply":"2023-05-04T23:25:16.236436Z","shell.execute_reply.started":"2023-05-04T23:25:14.102706Z"},"trusted":true},"outputs":[],"source":["gradcam_images(labels[10:15])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":23079,"sourceId":29550,"sourceType":"datasetVersion"}],"dockerImageVersionId":30476,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
